{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Animius Documentation \u00b6 Animius is a deep-learning-powered engine for creating virtual assistants. For experienced programmers, please refer to the Python API section. For using the console, please refer to the commands section. Some useful links: Animius website Installing Animius gundamMC/Animius on Github animius on PyPi gundammc/animius on Docker","title":"Home"},{"location":"#animius-documentation","text":"Animius is a deep-learning-powered engine for creating virtual assistants. For experienced programmers, please refer to the Python API section. For using the console, please refer to the commands section. Some useful links: Animius website Installing Animius gundamMC/Animius on Github animius on PyPi gundammc/animius on Docker","title":"Animius Documentation"},{"location":"about/","text":"De nec cadunt est undique illa ille \u00b6 Pecoris aequore \u00b6 Lorem markdownum laevum hoste, Arcton convocat sanesque silva agro, Pandione ego bellica ? Mihi esse obortis, in pondus sancta duratur uvae dum! Captus casside. Audete illi in rebus in adulantum tuli, in subde interserit, per. Quamvis et ferocis nostri lingua ! Cacumine tum paranti, praefractam haec spargit. Templi modo latentes duxerat et arma. Pone bene pectore forma Tiberinus animalia quamvis? Pectus sub iacit tuebere ad altior. 1 2 3 syncDrive.win_intranet = dns; var tcpSiteWrap = 5; smartTerminal.jqueryCpm += wordart; At aurea molibus \u00b6 Florem in est? Aera suo, sunto amas sanguine altaribus venter mea, nobis utque eras ab. Lucis est pectus catenas nequeunt unguibus pecudes lucis et patientem quae adiutis lacrimabile potest nubigenasque mente. Viri tuum nova positoque, illo sic, iusserat mihi caelo vivunt vel sepulti omnis locum volucrumque adde; fixa. Alte demittere ad inter poenam orbator. Discedite moenia sustinet officio mihi annis super, et honor et longum dempto postquam tot dolens! Tibi auras \u00b6 Tauros et inmensae tuo pumice moventur illo adflatuque signum ; ait media erat amans, auras? Gemitu Teucri Stabiasque dextris nate verba victor. Nate quam vellem, Turnus it mendacem datur Arethusa, dixerat referemus aevumque. 1 2 3 var source = disk(barcraftGrep, sectorWired, 80); web_hfs_bar += raw; hover_megabit(copyright_pcmcia, smishing, modem_hard_user + dvd / petabyte); Tollere parta. Dianam optima cum vasto sanguine Persei hospitio consorte animam. Animum pugnae unus pavidamque tellure, vetitorum crearit: quoque rex pater adiectoque quae verba coloribus milibus procul ; nimiumque. Mentem ut utque finibus Aesaris fiducia perfundit terrent est exiguam regna exsistunt, officium , Iunone. Qua cumque notas tuae damnantem ultima spissus quid hos sinit: inpensior.","title":"De nec cadunt est undique illa ille"},{"location":"about/#de-nec-cadunt-est-undique-illa-ille","text":"","title":"De nec cadunt est undique illa ille"},{"location":"about/#pecoris-aequore","text":"Lorem markdownum laevum hoste, Arcton convocat sanesque silva agro, Pandione ego bellica ? Mihi esse obortis, in pondus sancta duratur uvae dum! Captus casside. Audete illi in rebus in adulantum tuli, in subde interserit, per. Quamvis et ferocis nostri lingua ! Cacumine tum paranti, praefractam haec spargit. Templi modo latentes duxerat et arma. Pone bene pectore forma Tiberinus animalia quamvis? Pectus sub iacit tuebere ad altior. 1 2 3 syncDrive.win_intranet = dns; var tcpSiteWrap = 5; smartTerminal.jqueryCpm += wordart;","title":"Pecoris aequore"},{"location":"about/#at-aurea-molibus","text":"Florem in est? Aera suo, sunto amas sanguine altaribus venter mea, nobis utque eras ab. Lucis est pectus catenas nequeunt unguibus pecudes lucis et patientem quae adiutis lacrimabile potest nubigenasque mente. Viri tuum nova positoque, illo sic, iusserat mihi caelo vivunt vel sepulti omnis locum volucrumque adde; fixa. Alte demittere ad inter poenam orbator. Discedite moenia sustinet officio mihi annis super, et honor et longum dempto postquam tot dolens!","title":"At aurea molibus"},{"location":"about/#tibi-auras","text":"Tauros et inmensae tuo pumice moventur illo adflatuque signum ; ait media erat amans, auras? Gemitu Teucri Stabiasque dextris nate verba victor. Nate quam vellem, Turnus it mendacem datur Arethusa, dixerat referemus aevumque. 1 2 3 var source = disk(barcraftGrep, sectorWired, 80); web_hfs_bar += raw; hover_megabit(copyright_pcmcia, smishing, modem_hard_user + dvd / petabyte); Tollere parta. Dianam optima cum vasto sanguine Persei hospitio consorte animam. Animum pugnae unus pavidamque tellure, vetitorum crearit: quoque rex pater adiectoque quae verba coloribus milibus procul ; nimiumque. Mentem ut utque finibus Aesaris fiducia perfundit terrent est exiguam regna exsistunt, officium , Iunone. Qua cumque notas tuae damnantem ultima spissus quid hos sinit: inpensior.","title":"Tibi auras"},{"location":"commands/console/","text":"Console \u00b6 save \u00b6 Save the console. (This does not save individual items such as models and waifus.) 1 save No argument required. sliceAudio \u00b6 Loading subtitle and slicing audio. 1 sliceAudio -sp 'subtitle.ass' -ap 'test.mp3' -s 'some\\\\path\\\\save\\\\' -sp, --subtitle_path ( str ) -- Path to subtitle file -ap, --audio_path ( str ) -- Path to audio file -s, --save_path ( str ) -- Path to save audio","title":"Console"},{"location":"commands/console/#console","text":"","title":"Console"},{"location":"commands/console/#save","text":"Save the console. (This does not save individual items such as models and waifus.) 1 save No argument required.","title":"save"},{"location":"commands/console/#sliceaudio","text":"Loading subtitle and slicing audio. 1 sliceAudio -sp 'subtitle.ass' -ap 'test.mp3' -s 'some\\\\path\\\\save\\\\' -sp, --subtitle_path ( str ) -- Path to subtitle file -ap, --audio_path ( str ) -- Path to audio file -s, --save_path ( str ) -- Path to save audio","title":"sliceAudio"},{"location":"commands/data/","text":"Data \u00b6 Overview \u00b6 getData \u00b6 Get a list of existing data. 1 getData No argument required. createData \u00b6 Create a data with empty values. 1 createData -n 'data name' -t 'ModelType' -c 'model config name' Keyword Arguments: -n, --name ( str ) -- Name of data -t, --type ( str ) -- Type of data (based on the model) -c, --model_config ( str ) -- Name of model config dataAddEmbedding \u00b6 Add word embedding to data 1 dataAddEmbedding -n 'data name' -e 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -e, --embedding ( str ) -- Name of embedding dataReset \u00b6 Reset a data, clearing all stored data values. 1 dataReset -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data to reset deleteData \u00b6 Delete a data. 1 deleteData -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data to delete saveData \u00b6 Save a data. 1 saveData -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data to save loadData \u00b6 Load a data. 1 loadData -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data to load exportData \u00b6 Export a data to zip file. 1 exportData -n 'data name' -p 'some\\path\\to\\export\\' Keyword Arguments: -n, --name ( str ) -- Name of data to export -p, --path ( str ) -- Path to export file importData \u00b6 Import a data from zip file. 1 importModel - n 'data name' - p 'some\\path\\to\\export\\data_name.zip' Keyword Arguments: -n, --name ( str ) -- Name of data to import -p, --path ( str ) -- Path to import file getData \u00b6 Get a list of existing data. 1 getData No argument required. This command returns a dictionary of which the keys are the name of data and the values are the details. The details will be empty if the data is not loaded. 1 2 3 4 5 6 { \"data_name\": { \"name\": \"data_name\", \"type\": \"<class 'data _class'>\" } } getDataDetails \u00b6 Return the details of a data. 1 getDataDetails -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data 1 2 3 4 5 6 7 8 9 10 { 'model_config_saved_directory': 'resources\\\\model_configs', 'model_config_saved_name': 'model_config_name', 'model_config_name': 'model_config_name', 'embedding_saved_directory': 'resources\\\\embeddings\\\\embedding_name', 'embedding_saved_name': 'embedding_name', 'embedding_name': 'embedding_name', 'cls': 'ChatbotData', 'values': ['arr_0', 'embedding'] } Chatbot Data \u00b6 chatbotDataAddTwitter \u00b6 Add twitter dataset to a chatbot data. 1 chatbotDataAddTwitter -n 'data name' -p '\\some\\path\\twitter.txt' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -p, --path ( str ) -- Path to twitter file chatbotDataAddCornell \u00b6 Add Cornell dataset to a chatbot data. 1 chatbotDataAddCornell -n 'data name' -mcp '\\some\\cornell\\movie_conversations.txt' -mlp '\\some\\cornell\\movie_lines.txt' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -mcp, --movie_conversations_path ( str ) -- Path to movie_conversations.txt in the Cornell dataset -mlp, --movie_lines_path ( str ) -- Path to movie_lines.txt in the Cornell dataset chatbotDataAddParseSentences \u00b6 Parse raw sentences and add them to a chatbot data. 1 chatbotDataAddParseSentences -n 'data name' -x '[\"some input\"]' -y '[\"some output\"]' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -x, --x ( list<str> ) -- List of strings, each representing a sentence input -y, --y ( list<str> ) -- List of strings, each representing a sentence output chatbotDataAddParseFile \u00b6 Parse raw sentences from text files and add them to a chatbot data. 1 chatbotDataAddParseFile -n 'data name' -x '\\some\\path\\x.txt' -y '\\some\\path\\y.txt' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -x, --x_path ( str ) -- Path to a UTF-8 file containing a raw sentence input on each line -y, --y_path ( str ) -- Path to a UTF-8 file containing a raw sentence output on each line chatbotDataAddParseInput \u00b6 Parse a raw sentence as input and add it to a chatbot data. 1 chatbotDataAddParseInput -n 'data name' -x 'hey how are you' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -x, --x ( str ) -- Raw sentence input chatbotDataSetParseInput \u00b6 Parse a raw sentence as input and set it as a chatbot data. 1 chatbotDataSetParseInput -n 'data name' -x 'hey how are you' Keyword Arguments: -n, --name ( str ) -- Name of data to set -x, --x ( str ) -- Raw sentence input IntentNER Data \u00b6 intentNERDataAddParseDatafolder \u00b6 Parse files from a folder and add them to a chatbot data. 1 intentNERDataAddParseDatafolder -n 'data name' -p '\\some\\path\\to\\intents' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -p, --path ( str ) -- Path to a folder contains input files intentNERDataAddParseInput \u00b6 Parse a raw sentence as input and add it to an intent NER data. 1 intentNERDataAddParseInput -n 'data name' -x 'hey how are you' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -x, --x ( str ) -- Raw sentence input intentNERDataSetParseInput \u00b6 Parse a raw sentence as input and set it as an intent NER data. 1 intentNERDataSetParseInput -n 'data name' -x 'hey how are you' Keyword Arguments: -n, --name ( str ) -- Name of data to set -x, --x ( str ) -- Raw sentence input SpeakerVerification Data \u00b6 speakerVerificationDataAddDataPaths \u00b6 Parse and add raw audio files to a speaker verification data. 1 speakerVerificationDataAddDataPaths -n 'data name' -p '[\"\\some\\path\\01.wav\"]' [-y True] Keyword Arguments: -n, --name ( str ) -- Name of data to add on -p, -path ( list<str> ) -- List of string paths to raw audio files -y, --y ( bool ) -- The label (True for is speaker and vice versa) of the audio files. Include for training, leave out for prediction. (Optional) speakerVerificationDataAddDataFile \u00b6 Read paths to raw audio files and add them to a speaker verification data. 1 speakerVerificationDataAddDataFile -n 'data name' -p '\\some\\path\\audios.txt' -y True Keyword Arguments: -n, --name ( str ) -- Name of data to add on -p, --path ( str ) -- Path to file containing a path of a raw audio file on each line -y, --y ( bool ) -- The label (True for is speaker and vice versa) of the audio files. Include for training, leave out for prediction. (Optional)","title":"Data"},{"location":"commands/data/#data","text":"","title":"Data"},{"location":"commands/data/#overview","text":"","title":"Overview"},{"location":"commands/data/#getdata","text":"Get a list of existing data. 1 getData No argument required.","title":"getData"},{"location":"commands/data/#createdata","text":"Create a data with empty values. 1 createData -n 'data name' -t 'ModelType' -c 'model config name' Keyword Arguments: -n, --name ( str ) -- Name of data -t, --type ( str ) -- Type of data (based on the model) -c, --model_config ( str ) -- Name of model config","title":"createData"},{"location":"commands/data/#dataaddembedding","text":"Add word embedding to data 1 dataAddEmbedding -n 'data name' -e 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -e, --embedding ( str ) -- Name of embedding","title":"dataAddEmbedding"},{"location":"commands/data/#datareset","text":"Reset a data, clearing all stored data values. 1 dataReset -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data to reset","title":"dataReset"},{"location":"commands/data/#deletedata","text":"Delete a data. 1 deleteData -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data to delete","title":"deleteData"},{"location":"commands/data/#savedata","text":"Save a data. 1 saveData -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data to save","title":"saveData"},{"location":"commands/data/#loaddata","text":"Load a data. 1 loadData -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data to load","title":"loadData"},{"location":"commands/data/#exportdata","text":"Export a data to zip file. 1 exportData -n 'data name' -p 'some\\path\\to\\export\\' Keyword Arguments: -n, --name ( str ) -- Name of data to export -p, --path ( str ) -- Path to export file","title":"exportData"},{"location":"commands/data/#importdata","text":"Import a data from zip file. 1 importModel - n 'data name' - p 'some\\path\\to\\export\\data_name.zip' Keyword Arguments: -n, --name ( str ) -- Name of data to import -p, --path ( str ) -- Path to import file","title":"importData"},{"location":"commands/data/#getdata_1","text":"Get a list of existing data. 1 getData No argument required. This command returns a dictionary of which the keys are the name of data and the values are the details. The details will be empty if the data is not loaded. 1 2 3 4 5 6 { \"data_name\": { \"name\": \"data_name\", \"type\": \"<class 'data _class'>\" } }","title":"getData"},{"location":"commands/data/#getdatadetails","text":"Return the details of a data. 1 getDataDetails -n 'data name' Keyword Arguments: -n, --name ( str ) -- Name of data 1 2 3 4 5 6 7 8 9 10 { 'model_config_saved_directory': 'resources\\\\model_configs', 'model_config_saved_name': 'model_config_name', 'model_config_name': 'model_config_name', 'embedding_saved_directory': 'resources\\\\embeddings\\\\embedding_name', 'embedding_saved_name': 'embedding_name', 'embedding_name': 'embedding_name', 'cls': 'ChatbotData', 'values': ['arr_0', 'embedding'] }","title":"getDataDetails"},{"location":"commands/data/#chatbot-data","text":"","title":"Chatbot Data"},{"location":"commands/data/#chatbotdataaddtwitter","text":"Add twitter dataset to a chatbot data. 1 chatbotDataAddTwitter -n 'data name' -p '\\some\\path\\twitter.txt' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -p, --path ( str ) -- Path to twitter file","title":"chatbotDataAddTwitter"},{"location":"commands/data/#chatbotdataaddcornell","text":"Add Cornell dataset to a chatbot data. 1 chatbotDataAddCornell -n 'data name' -mcp '\\some\\cornell\\movie_conversations.txt' -mlp '\\some\\cornell\\movie_lines.txt' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -mcp, --movie_conversations_path ( str ) -- Path to movie_conversations.txt in the Cornell dataset -mlp, --movie_lines_path ( str ) -- Path to movie_lines.txt in the Cornell dataset","title":"chatbotDataAddCornell"},{"location":"commands/data/#chatbotdataaddparsesentences","text":"Parse raw sentences and add them to a chatbot data. 1 chatbotDataAddParseSentences -n 'data name' -x '[\"some input\"]' -y '[\"some output\"]' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -x, --x ( list<str> ) -- List of strings, each representing a sentence input -y, --y ( list<str> ) -- List of strings, each representing a sentence output","title":"chatbotDataAddParseSentences"},{"location":"commands/data/#chatbotdataaddparsefile","text":"Parse raw sentences from text files and add them to a chatbot data. 1 chatbotDataAddParseFile -n 'data name' -x '\\some\\path\\x.txt' -y '\\some\\path\\y.txt' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -x, --x_path ( str ) -- Path to a UTF-8 file containing a raw sentence input on each line -y, --y_path ( str ) -- Path to a UTF-8 file containing a raw sentence output on each line","title":"chatbotDataAddParseFile"},{"location":"commands/data/#chatbotdataaddparseinput","text":"Parse a raw sentence as input and add it to a chatbot data. 1 chatbotDataAddParseInput -n 'data name' -x 'hey how are you' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -x, --x ( str ) -- Raw sentence input","title":"chatbotDataAddParseInput"},{"location":"commands/data/#chatbotdatasetparseinput","text":"Parse a raw sentence as input and set it as a chatbot data. 1 chatbotDataSetParseInput -n 'data name' -x 'hey how are you' Keyword Arguments: -n, --name ( str ) -- Name of data to set -x, --x ( str ) -- Raw sentence input","title":"chatbotDataSetParseInput"},{"location":"commands/data/#intentner-data","text":"","title":"IntentNER Data"},{"location":"commands/data/#intentnerdataaddparsedatafolder","text":"Parse files from a folder and add them to a chatbot data. 1 intentNERDataAddParseDatafolder -n 'data name' -p '\\some\\path\\to\\intents' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -p, --path ( str ) -- Path to a folder contains input files","title":"intentNERDataAddParseDatafolder"},{"location":"commands/data/#intentnerdataaddparseinput","text":"Parse a raw sentence as input and add it to an intent NER data. 1 intentNERDataAddParseInput -n 'data name' -x 'hey how are you' Keyword Arguments: -n, --name ( str ) -- Name of data to add on -x, --x ( str ) -- Raw sentence input","title":"intentNERDataAddParseInput"},{"location":"commands/data/#intentnerdatasetparseinput","text":"Parse a raw sentence as input and set it as an intent NER data. 1 intentNERDataSetParseInput -n 'data name' -x 'hey how are you' Keyword Arguments: -n, --name ( str ) -- Name of data to set -x, --x ( str ) -- Raw sentence input","title":"intentNERDataSetParseInput"},{"location":"commands/data/#speakerverification-data","text":"","title":"SpeakerVerification Data"},{"location":"commands/data/#speakerverificationdataadddatapaths","text":"Parse and add raw audio files to a speaker verification data. 1 speakerVerificationDataAddDataPaths -n 'data name' -p '[\"\\some\\path\\01.wav\"]' [-y True] Keyword Arguments: -n, --name ( str ) -- Name of data to add on -p, -path ( list<str> ) -- List of string paths to raw audio files -y, --y ( bool ) -- The label (True for is speaker and vice versa) of the audio files. Include for training, leave out for prediction. (Optional)","title":"speakerVerificationDataAddDataPaths"},{"location":"commands/data/#speakerverificationdataadddatafile","text":"Read paths to raw audio files and add them to a speaker verification data. 1 speakerVerificationDataAddDataFile -n 'data name' -p '\\some\\path\\audios.txt' -y True Keyword Arguments: -n, --name ( str ) -- Name of data to add on -p, --path ( str ) -- Path to file containing a path of a raw audio file on each line -y, --y ( bool ) -- The label (True for is speaker and vice versa) of the audio files. Include for training, leave out for prediction. (Optional)","title":"speakerVerificationDataAddDataFile"},{"location":"commands/embedding/","text":"Embedding \u00b6 getEmbeddings \u00b6 Get a list of existing word embeddings. 1 getEmbeddings No argument required. createEmbedding \u00b6 Create a word embedding. 1 createEmbedding -n 'embedding name' -p '\\some\\path\\embedding.txt' [-v 100000] Keyword Arguments: -n, --name ( str ) -- Name of embedding -p, --path ( str ) -- Path to embedding file -v, --vocab_size ( int ) -- Maximum number of tokens to read from embedding file (Optional) deleteEmbedding \u00b6 Delete a word embedding. 1 deleteEmbedding -n 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of embedding to delete saveEmbedding \u00b6 Save an embedding. 1 saveEmbedding -n 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of embedding to save loadEmbedding \u00b6 Load an embedding. 1 loadEmbedding -n 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of embedding to load exportEmbedding \u00b6 Export an embedding to zip file. 1 exportEmbedding -n 'embedding name' -p 'some\\path\\to\\export\\' Keyword Arguments: -n, --name ( str ) -- Name of embedding to export -p, --path ( str ) -- Path to export file importEmbedding \u00b6 Import an embedding from zip file. 1 importModel - n 'embedding name' - p 'some\\path\\to\\export\\embedding_name.zip' Keyword Arguments: -n, --name ( str ) -- Name of embedding to import -p, --path ( str ) -- Path to import file getEmbeddings \u00b6 Get a list of existing embedding. 1 getEmbeddings No argument required. This command returns a dictionary of which the keys are the name of embeddings and the values are the details. The details will be empty if the embedding is not loaded. 1 2 3 4 5 { \"embedding_name\": { \"name\": \"embedding_name\" } } getEmbeddingDetails \u00b6 Return the details of an embedding. 1 getEmbeddingDetails -n 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of embedding 1 2 3 4 5 { 'name': 'embedding_name', 'saved_directory': 'resources\\\\embeddings\\\\embedding_name', 'saved_name': 'embedding_name' }","title":"Embedding"},{"location":"commands/embedding/#embedding","text":"","title":"Embedding"},{"location":"commands/embedding/#getembeddings","text":"Get a list of existing word embeddings. 1 getEmbeddings No argument required.","title":"getEmbeddings"},{"location":"commands/embedding/#createembedding","text":"Create a word embedding. 1 createEmbedding -n 'embedding name' -p '\\some\\path\\embedding.txt' [-v 100000] Keyword Arguments: -n, --name ( str ) -- Name of embedding -p, --path ( str ) -- Path to embedding file -v, --vocab_size ( int ) -- Maximum number of tokens to read from embedding file (Optional)","title":"createEmbedding"},{"location":"commands/embedding/#deleteembedding","text":"Delete a word embedding. 1 deleteEmbedding -n 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of embedding to delete","title":"deleteEmbedding"},{"location":"commands/embedding/#saveembedding","text":"Save an embedding. 1 saveEmbedding -n 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of embedding to save","title":"saveEmbedding"},{"location":"commands/embedding/#loadembedding","text":"Load an embedding. 1 loadEmbedding -n 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of embedding to load","title":"loadEmbedding"},{"location":"commands/embedding/#exportembedding","text":"Export an embedding to zip file. 1 exportEmbedding -n 'embedding name' -p 'some\\path\\to\\export\\' Keyword Arguments: -n, --name ( str ) -- Name of embedding to export -p, --path ( str ) -- Path to export file","title":"exportEmbedding"},{"location":"commands/embedding/#importembedding","text":"Import an embedding from zip file. 1 importModel - n 'embedding name' - p 'some\\path\\to\\export\\embedding_name.zip' Keyword Arguments: -n, --name ( str ) -- Name of embedding to import -p, --path ( str ) -- Path to import file","title":"importEmbedding"},{"location":"commands/embedding/#getembeddings_1","text":"Get a list of existing embedding. 1 getEmbeddings No argument required. This command returns a dictionary of which the keys are the name of embeddings and the values are the details. The details will be empty if the embedding is not loaded. 1 2 3 4 5 { \"embedding_name\": { \"name\": \"embedding_name\" } }","title":"getEmbeddings"},{"location":"commands/embedding/#getembeddingdetails","text":"Return the details of an embedding. 1 getEmbeddingDetails -n 'embedding name' Keyword Arguments: -n, --name ( str ) -- Name of embedding 1 2 3 4 5 { 'name': 'embedding_name', 'saved_directory': 'resources\\\\embeddings\\\\embedding_name', 'saved_name': 'embedding_name' }","title":"getEmbeddingDetails"},{"location":"commands/model config/","text":"Model Config \u00b6 createModelConfig \u00b6 Create a model config with the provided values. 1 createModelConfig -n 'model config name' -t 'type' [-c '{\"some_key\": \"some_value\"}'] [-h '{}'] [-ms '{}'] Keyword Arguements: -n, --name ( str ) -- Name of model config -t, --type ( str ) -- Name of the model type -c, --config ( dict ) -- Dictionary of config values (Optional) -h, --hyperparameters ( dict ) -- Dictionary of hyperparameters values (Optional) -s, --model_structure ( dict ) -- Dictionary of model_structure values (Optional) editModelConfig \u00b6 Update a model config with provided values. Either providing full dict of configs or changing specific values is allowed. 1 2 3 editModelConfig -n 'model config name' [-c '{\"some_key\": \"some_value\"}'] [-h '{}'] [-s '{}'] editModelConfig -n 'model config name' [-bs 1024] [-lr 0.1] [-d '/gpu:0'] Keyword Arguments: -n, --name ( str ) -- Name of model config to edit -c, --config ( dict ) -- Dictionary containing the updated config values (Optional) -h, --hyperparameters ( dict ) -- Dictionary containing the updated hyperparameters values (Optional) -s, --model_structure ( dict ) -- Dictionary containing the updated model structure values (Optional) -d, --device ( str ) -- Name of device to use (Optional) -cls, --class ( str ) -- Model class (Optional) -e, --epoch ( int ) -- Number of epoches (Optional) -cost, --cost (``) -- config.cost (Optional) -ds, --display_step (``) -- config.display_step (Optional) -tb, --tensorboard (``) -- config.tensorboard (Optional) -lr, --learning_rate ( float ) -- Learning rate (Optional) -bs, --batch_size ( int ) -- Batch size (Optional) -op, --optimizer ( str ) -- Name of optimizer (Optional) -ms, --max_sequence ( int ) -- model_structure.max_sequence (Optional) -nh, --n_hidden ( int ) -- model_structure.n_hidden (Optional) -gc, --gradient_clip ( float ) -- model_structure.gradient_clip (Optional) -no, --node ( str ) -- model_structure.node (Optional) -nio, --n_intent_output ( int ) -- model_structure.n_intent_output (Optional) -nno, --n_ner_output ( int ) -- model_structure.n_ner_output (Optional) -l, --layer ( int ) -- Number of layers (Optional) -bw, --beam_width ( int ) -- Beam width (Optional) -fs1, --filter_size_1 ( int ) -- model_structure.filter_size_1 (Optional) -fs2, --filter_size_2 ( int ) -- model_structure.filter_size_2 (Optional) -nf1, --num_filter_1 ( int ) -- model_structure.num_filter_1 (Optional) -nf2, --num_filter_2 ( int ) -- model_structure.num_filter_2 (Optional) -ps1, --pool_size_1 ( int ) -- model_structure.pool_size_1 (Optional) -pt, --pool_type ( str ) -- model_structure.pool_type (Optional) -fc1, --fully_connected_1 ( int ) -- model_structure.fully_connect_1 (Optional) -iw, --input_window ( int ) -- model_structure.input_window (Optional) -ic, --input_cepstral ( int ) -- model_structure.input_cepstral (Optional) deleteModelConfig \u00b6 Delete a model config. 1 deleteModelConfig -n 'model config name' Keyword Argument: -n, --name ( str ) -- Name of model config to delete saveModelConfig \u00b6 Save a model config. 1 saveModelConfig -n 'model config name' Keyword Argument: -n, --name ( str ) -- Name of model config to save loadModelConfig \u00b6 Load a model config. 1 loadModelConfig -n 'model config name' Keyword Argument: -n, --name ( str ) -- Name of model config to load exportModelConfig \u00b6 Export a model config to zip file. 1 exportModelConfig -n 'model config name' -p 'some\\path\\to\\export\\' Keyword Arguments: -n, --name ( str ) -- Name of model config to export -p, --path ( str ) -- Path to export file importModelConfig \u00b6 Import a model config from zip file. 1 importModel - n 'model name' - p 'some\\path\\to\\export\\model_name.zip' Keyword Arguments: -n, --name ( str ) -- Name of model config to export -p, --path ( str ) -- Path to import file getModelConfigs \u00b6 Get a list of existing model configs. 1 getModelConfigs No argument required. The details will be empty if the model is not loaded. 1 2 3 4 5 { \"model_config_name\": { \"name\": \"model_config_name\" } } getModelConfigDetails \u00b6 Get the details of a model config. 1 getModelConfigDetails -n 'model config name' Keyword Arguments: -n, --name ( str ) -- Name of model config This command returns a dictionary of details of a model config, which contains configs, hyperparameters, structures, saved name and saved directory of the model config. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { 'config': { 'device': '/gpu:0', 'class': 'IntentNER', 'epoch': 0, 'cost': None, 'display_step': 1, 'tensorboard': None, 'hyperdash': None, 'graph': 'resources\\\\models\\\\model_name\\\\model_name_graph.pb', 'frozen_graph': 'resources\\\\models\\\\model_name\\\\frozen_model.pb' }, 'model_structure': { 'max_sequence': 20, 'n_hidden': 128, 'gradient_clip': 5.0, 'node': 'gru', 'n_intent_output': 15, 'n_ner_output': 8, 'n_vector': 303, 'word_count': 100000 }, 'hyperparamter': { 'learning_rate': 0.003, 'batch_size': 1024, 'optimizer': 'adam' }, 'saved_directory': 'resources\\\\models\\\\model_name', 'saved_name': 'model_name' }","title":"Model Config"},{"location":"commands/model config/#model-config","text":"","title":"Model Config"},{"location":"commands/model config/#createmodelconfig","text":"Create a model config with the provided values. 1 createModelConfig -n 'model config name' -t 'type' [-c '{\"some_key\": \"some_value\"}'] [-h '{}'] [-ms '{}'] Keyword Arguements: -n, --name ( str ) -- Name of model config -t, --type ( str ) -- Name of the model type -c, --config ( dict ) -- Dictionary of config values (Optional) -h, --hyperparameters ( dict ) -- Dictionary of hyperparameters values (Optional) -s, --model_structure ( dict ) -- Dictionary of model_structure values (Optional)","title":"createModelConfig"},{"location":"commands/model config/#editmodelconfig","text":"Update a model config with provided values. Either providing full dict of configs or changing specific values is allowed. 1 2 3 editModelConfig -n 'model config name' [-c '{\"some_key\": \"some_value\"}'] [-h '{}'] [-s '{}'] editModelConfig -n 'model config name' [-bs 1024] [-lr 0.1] [-d '/gpu:0'] Keyword Arguments: -n, --name ( str ) -- Name of model config to edit -c, --config ( dict ) -- Dictionary containing the updated config values (Optional) -h, --hyperparameters ( dict ) -- Dictionary containing the updated hyperparameters values (Optional) -s, --model_structure ( dict ) -- Dictionary containing the updated model structure values (Optional) -d, --device ( str ) -- Name of device to use (Optional) -cls, --class ( str ) -- Model class (Optional) -e, --epoch ( int ) -- Number of epoches (Optional) -cost, --cost (``) -- config.cost (Optional) -ds, --display_step (``) -- config.display_step (Optional) -tb, --tensorboard (``) -- config.tensorboard (Optional) -lr, --learning_rate ( float ) -- Learning rate (Optional) -bs, --batch_size ( int ) -- Batch size (Optional) -op, --optimizer ( str ) -- Name of optimizer (Optional) -ms, --max_sequence ( int ) -- model_structure.max_sequence (Optional) -nh, --n_hidden ( int ) -- model_structure.n_hidden (Optional) -gc, --gradient_clip ( float ) -- model_structure.gradient_clip (Optional) -no, --node ( str ) -- model_structure.node (Optional) -nio, --n_intent_output ( int ) -- model_structure.n_intent_output (Optional) -nno, --n_ner_output ( int ) -- model_structure.n_ner_output (Optional) -l, --layer ( int ) -- Number of layers (Optional) -bw, --beam_width ( int ) -- Beam width (Optional) -fs1, --filter_size_1 ( int ) -- model_structure.filter_size_1 (Optional) -fs2, --filter_size_2 ( int ) -- model_structure.filter_size_2 (Optional) -nf1, --num_filter_1 ( int ) -- model_structure.num_filter_1 (Optional) -nf2, --num_filter_2 ( int ) -- model_structure.num_filter_2 (Optional) -ps1, --pool_size_1 ( int ) -- model_structure.pool_size_1 (Optional) -pt, --pool_type ( str ) -- model_structure.pool_type (Optional) -fc1, --fully_connected_1 ( int ) -- model_structure.fully_connect_1 (Optional) -iw, --input_window ( int ) -- model_structure.input_window (Optional) -ic, --input_cepstral ( int ) -- model_structure.input_cepstral (Optional)","title":"editModelConfig"},{"location":"commands/model config/#deletemodelconfig","text":"Delete a model config. 1 deleteModelConfig -n 'model config name' Keyword Argument: -n, --name ( str ) -- Name of model config to delete","title":"deleteModelConfig"},{"location":"commands/model config/#savemodelconfig","text":"Save a model config. 1 saveModelConfig -n 'model config name' Keyword Argument: -n, --name ( str ) -- Name of model config to save","title":"saveModelConfig"},{"location":"commands/model config/#loadmodelconfig","text":"Load a model config. 1 loadModelConfig -n 'model config name' Keyword Argument: -n, --name ( str ) -- Name of model config to load","title":"loadModelConfig"},{"location":"commands/model config/#exportmodelconfig","text":"Export a model config to zip file. 1 exportModelConfig -n 'model config name' -p 'some\\path\\to\\export\\' Keyword Arguments: -n, --name ( str ) -- Name of model config to export -p, --path ( str ) -- Path to export file","title":"exportModelConfig"},{"location":"commands/model config/#importmodelconfig","text":"Import a model config from zip file. 1 importModel - n 'model name' - p 'some\\path\\to\\export\\model_name.zip' Keyword Arguments: -n, --name ( str ) -- Name of model config to export -p, --path ( str ) -- Path to import file","title":"importModelConfig"},{"location":"commands/model config/#getmodelconfigs","text":"Get a list of existing model configs. 1 getModelConfigs No argument required. The details will be empty if the model is not loaded. 1 2 3 4 5 { \"model_config_name\": { \"name\": \"model_config_name\" } }","title":"getModelConfigs"},{"location":"commands/model config/#getmodelconfigdetails","text":"Get the details of a model config. 1 getModelConfigDetails -n 'model config name' Keyword Arguments: -n, --name ( str ) -- Name of model config This command returns a dictionary of details of a model config, which contains configs, hyperparameters, structures, saved name and saved directory of the model config. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { 'config': { 'device': '/gpu:0', 'class': 'IntentNER', 'epoch': 0, 'cost': None, 'display_step': 1, 'tensorboard': None, 'hyperdash': None, 'graph': 'resources\\\\models\\\\model_name\\\\model_name_graph.pb', 'frozen_graph': 'resources\\\\models\\\\model_name\\\\frozen_model.pb' }, 'model_structure': { 'max_sequence': 20, 'n_hidden': 128, 'gradient_clip': 5.0, 'node': 'gru', 'n_intent_output': 15, 'n_ner_output': 8, 'n_vector': 303, 'word_count': 100000 }, 'hyperparamter': { 'learning_rate': 0.003, 'batch_size': 1024, 'optimizer': 'adam' }, 'saved_directory': 'resources\\\\models\\\\model_name', 'saved_name': 'model_name' }","title":"getModelConfigDetails"},{"location":"commands/model/","text":"Model \u00b6 The following section describe the commands related to Models. Defined in animius\\Console.py createModel \u00b6 Create a model. 1 createModel -n 'model name' -t 'ModelType' -c 'model_config name' -d 'data name' Keyword Arguments: -n, --name ( str ) -- Name of model -t, --type ( str ) -- Type of model -c, --model_config ( str ) -- Name of model config to use -d, --data ( str ) -- Name of data to use -i, --intent_ner_model * ( str ) -- (Optional) Name of IntentNER Model (Only required for creating CombinedChatbot Model) Here's a list of model types. Chatbot: am.Chatbot.ChatbotModel() CombinedChatbot: animius.Chatbot.CombinedChatbotModel() IntentNER: animius.IntentNER.IntentNERModel() SpeakerVerification: animius.SpeakerVerification.SpeakerVerificationModel() deleteModel \u00b6 Delete a model. 1 deleteModel -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model to delete saveModel \u00b6 Save a model. The graph is saved in '\\resource\\model_name\\model_name_graph.pb' 1 saveModel -n 'model name' -g True Keyword Arguments: -n, --name ( str ) -- Name of model to save -g, --graph ( bool ) -- Whether to save the graph loadModel \u00b6 Load a model. 1 loadModel -n 'model name' -d 'data name' Keyword Arguments: -n, --name ( str ) -- Name of model to load -d, --data ( str ) -- Name of data to set to model exportModel \u00b6 Export a model to zip file. 1 exportModel -n 'model name' -p 'some\\path\\to\\export\\' Keyword Arguments: -n, --name ( str ) -- Name of model to export -p, --path ( str ) -- Path to export file importModel \u00b6 Import a model from zip file. 1 importModel - n 'model name' - p 'some\\path\\to\\export\\model_name.zip' Keyword Arguments: -n, --name ( str ) -- Name of model to export -p, --path ( str ) -- Path to import file getModels \u00b6 Get a list of existing models. 1 getModels No argument required. This command returns a dictionary of which the keys are the name of models and the values are the details. The details will be empty if the model is not loaded. 1 2 3 4 5 6 { \"model_name\": { \"name\": \"model_name\", \"type\": \"<class 'model_class'>\" } } getModelDetails \u00b6 Get the details of a model. 1 getModelDetails -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model This command returns a dictionary of details of a model, which contains configs, hyperparameters, structures, saved name and saved directory of the model. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { 'config': { 'device': '/gpu:0', 'class': 'IntentNER', 'epoch': 0, 'cost': None, 'display_step': 1, 'tensorboard': None, 'hyperdash': None, 'graph': 'resources\\\\models\\\\model_name\\\\model_name_graph.pb', 'frozen_graph': 'resources\\\\models\\\\model_name\\\\frozen_model.pb' }, 'model_structure': { 'max_sequence': 20, 'n_hidden': 128, 'gradient_clip': 5.0, 'node': 'gru', 'n_intent_output': 15, 'n_ner_output': 8, 'n_vector': 303, 'word_count': 100000 }, 'hyperparamter': { 'learning_rate': 0.003, 'batch_size': 1024, 'optimizer': 'adam' }, 'saved_directory': 'resources\\\\models\\\\model_name', 'saved_name': 'model_name' } setData \u00b6 Set model data. 1 setData -n 'model name' -d 'data name' Keyword Arguments: -n, --name ( str ) -- Name of model -d, --data ( str ) -- Name of data train \u00b6 Train a model. The training process will be held in another thread. The training device is defined in the model config. 1 train -n 'model name' -e 10 Keyword Arguments: -n, --name ( str ) -- Name of model to train -e, --epoch ( int ) -- Number of epochs to train for stopTraining \u00b6 Cancel training a model. The model will stop once it finishes the current epoch. 1 stopTraining -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model to stop predict \u00b6 Make predictions with a model. 1 predict -n 'model name' -i 'name of input data' -s '\\some\\path.txt' Keyword Arguments: -n, --name ( str ) -- Name of model -i, --input_data ( str ) -- Name of input data -s, --save_path ( str ) -- Path to save result (Optional) freezeGraph \u00b6 Freeze Tensorflow graph and latest checkpoint to 'resource\\model_name\\frozen_model.pb'. 1 freezeGraph -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model optimize \u00b6 Optimize a frozen model (see FreezeGraph) for inference. 1 optimize -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model","title":"Model"},{"location":"commands/model/#model","text":"The following section describe the commands related to Models. Defined in animius\\Console.py","title":"Model"},{"location":"commands/model/#createmodel","text":"Create a model. 1 createModel -n 'model name' -t 'ModelType' -c 'model_config name' -d 'data name' Keyword Arguments: -n, --name ( str ) -- Name of model -t, --type ( str ) -- Type of model -c, --model_config ( str ) -- Name of model config to use -d, --data ( str ) -- Name of data to use -i, --intent_ner_model * ( str ) -- (Optional) Name of IntentNER Model (Only required for creating CombinedChatbot Model) Here's a list of model types. Chatbot: am.Chatbot.ChatbotModel() CombinedChatbot: animius.Chatbot.CombinedChatbotModel() IntentNER: animius.IntentNER.IntentNERModel() SpeakerVerification: animius.SpeakerVerification.SpeakerVerificationModel()","title":"createModel"},{"location":"commands/model/#deletemodel","text":"Delete a model. 1 deleteModel -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model to delete","title":"deleteModel"},{"location":"commands/model/#savemodel","text":"Save a model. The graph is saved in '\\resource\\model_name\\model_name_graph.pb' 1 saveModel -n 'model name' -g True Keyword Arguments: -n, --name ( str ) -- Name of model to save -g, --graph ( bool ) -- Whether to save the graph","title":"saveModel"},{"location":"commands/model/#loadmodel","text":"Load a model. 1 loadModel -n 'model name' -d 'data name' Keyword Arguments: -n, --name ( str ) -- Name of model to load -d, --data ( str ) -- Name of data to set to model","title":"loadModel"},{"location":"commands/model/#exportmodel","text":"Export a model to zip file. 1 exportModel -n 'model name' -p 'some\\path\\to\\export\\' Keyword Arguments: -n, --name ( str ) -- Name of model to export -p, --path ( str ) -- Path to export file","title":"exportModel"},{"location":"commands/model/#importmodel","text":"Import a model from zip file. 1 importModel - n 'model name' - p 'some\\path\\to\\export\\model_name.zip' Keyword Arguments: -n, --name ( str ) -- Name of model to export -p, --path ( str ) -- Path to import file","title":"importModel"},{"location":"commands/model/#getmodels","text":"Get a list of existing models. 1 getModels No argument required. This command returns a dictionary of which the keys are the name of models and the values are the details. The details will be empty if the model is not loaded. 1 2 3 4 5 6 { \"model_name\": { \"name\": \"model_name\", \"type\": \"<class 'model_class'>\" } }","title":"getModels"},{"location":"commands/model/#getmodeldetails","text":"Get the details of a model. 1 getModelDetails -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model This command returns a dictionary of details of a model, which contains configs, hyperparameters, structures, saved name and saved directory of the model. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { 'config': { 'device': '/gpu:0', 'class': 'IntentNER', 'epoch': 0, 'cost': None, 'display_step': 1, 'tensorboard': None, 'hyperdash': None, 'graph': 'resources\\\\models\\\\model_name\\\\model_name_graph.pb', 'frozen_graph': 'resources\\\\models\\\\model_name\\\\frozen_model.pb' }, 'model_structure': { 'max_sequence': 20, 'n_hidden': 128, 'gradient_clip': 5.0, 'node': 'gru', 'n_intent_output': 15, 'n_ner_output': 8, 'n_vector': 303, 'word_count': 100000 }, 'hyperparamter': { 'learning_rate': 0.003, 'batch_size': 1024, 'optimizer': 'adam' }, 'saved_directory': 'resources\\\\models\\\\model_name', 'saved_name': 'model_name' }","title":"getModelDetails"},{"location":"commands/model/#setdata","text":"Set model data. 1 setData -n 'model name' -d 'data name' Keyword Arguments: -n, --name ( str ) -- Name of model -d, --data ( str ) -- Name of data","title":"setData"},{"location":"commands/model/#train","text":"Train a model. The training process will be held in another thread. The training device is defined in the model config. 1 train -n 'model name' -e 10 Keyword Arguments: -n, --name ( str ) -- Name of model to train -e, --epoch ( int ) -- Number of epochs to train for","title":"train"},{"location":"commands/model/#stoptraining","text":"Cancel training a model. The model will stop once it finishes the current epoch. 1 stopTraining -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model to stop","title":"stopTraining"},{"location":"commands/model/#predict","text":"Make predictions with a model. 1 predict -n 'model name' -i 'name of input data' -s '\\some\\path.txt' Keyword Arguments: -n, --name ( str ) -- Name of model -i, --input_data ( str ) -- Name of input data -s, --save_path ( str ) -- Path to save result (Optional)","title":"predict"},{"location":"commands/model/#freezegraph","text":"Freeze Tensorflow graph and latest checkpoint to 'resource\\model_name\\frozen_model.pb'. 1 freezeGraph -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model","title":"freezeGraph"},{"location":"commands/model/#optimize","text":"Optimize a frozen model (see FreezeGraph) for inference. 1 optimize -n 'model name' Keyword Arguments: -n, --name ( str ) -- Name of model","title":"optimize"},{"location":"commands/overview/","text":"Commands Overview \u00b6 Commands are used to interact with the console as well as through the network socket. A command has two parts: the command and the arguments. In the console, a command could look something like this: 1 createModel --name 'myModel' --type 'SpeakerVerification' The equivalent of this in the network server would be: 1 2 3 4 5 6 7 { \"command\" : \"createModel\" , \"arguments\" : { \"name\" : \"myModel\" , \"type\" : \"SpeakerVerification\" } } The various commands and their arguments can be found in this section. Network-socket-related commands can be found under the Network section .","title":"Overview"},{"location":"commands/overview/#commands-overview","text":"Commands are used to interact with the console as well as through the network socket. A command has two parts: the command and the arguments. In the console, a command could look something like this: 1 createModel --name 'myModel' --type 'SpeakerVerification' The equivalent of this in the network server would be: 1 2 3 4 5 6 7 { \"command\" : \"createModel\" , \"arguments\" : { \"name\" : \"myModel\" , \"type\" : \"SpeakerVerification\" } } The various commands and their arguments can be found in this section. Network-socket-related commands can be found under the Network section .","title":"Commands Overview"},{"location":"commands/server/","text":"Server \u00b6 See Network for details. startServer \u00b6 Start a socket server and listen for clients. The server runs on a separate thread so the console will still function. 1 startServer -p 23333 [-l True] [-pwd 'p@ssword'] [-c 10] Keyword Arguments: -p, --port ( int ) -- Port to listen on -l, --local ( bool ) -- If the server is running locally (server will listen on 127.0.0.1 if this is true or not set) (Optional) -pwd, --password ( str ) -- Password of server (Optional) -c, --max_clients ( int ) -- Maximum number of clients (Optional) stopServer \u00b6 Stop current socket server and close all connections. 1 stopServer No argument required.","title":"Server"},{"location":"commands/server/#server","text":"See Network for details.","title":"Server"},{"location":"commands/server/#startserver","text":"Start a socket server and listen for clients. The server runs on a separate thread so the console will still function. 1 startServer -p 23333 [-l True] [-pwd 'p@ssword'] [-c 10] Keyword Arguments: -p, --port ( int ) -- Port to listen on -l, --local ( bool ) -- If the server is running locally (server will listen on 127.0.0.1 if this is true or not set) (Optional) -pwd, --password ( str ) -- Password of server (Optional) -c, --max_clients ( int ) -- Maximum number of clients (Optional)","title":"startServer"},{"location":"commands/server/#stopserver","text":"Stop current socket server and close all connections. 1 stopServer No argument required.","title":"stopServer"},{"location":"commands/waifu/","text":"Waifu \u00b6 getWaifu \u00b6 Get a list of existing waifu. 1 getWaifu No argument required. createWaifu \u00b6 Create a waifu. 1 createWaifu -n 'waifu name' -c 'name of model' -e 'name of embedding' Keyword Arguments: -n, --name ( str ) -- Name of waifu -c, --combined_chatbot_model ( str ) -- Name or directory of combined chatbot model to use -e, --embedding ( str ) -- Name of word embedding to use deleteWaifu \u00b6 Delete a waifu. 1 deleteWaifu -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu to delete saveWaifu \u00b6 Save a waifu. 1 saveWaifu -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu to save loadWaifu \u00b6 Load a waifu. 1 loadWaifu -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu to load getWaifuDetail \u00b6 Get the detail information of a waifu. 1 getWaifuDetail -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu waifuPredict \u00b6 Make prediction using waifu. 1 getWaifuDetail -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu","title":"Waifu"},{"location":"commands/waifu/#waifu","text":"","title":"Waifu"},{"location":"commands/waifu/#getwaifu","text":"Get a list of existing waifu. 1 getWaifu No argument required.","title":"getWaifu"},{"location":"commands/waifu/#createwaifu","text":"Create a waifu. 1 createWaifu -n 'waifu name' -c 'name of model' -e 'name of embedding' Keyword Arguments: -n, --name ( str ) -- Name of waifu -c, --combined_chatbot_model ( str ) -- Name or directory of combined chatbot model to use -e, --embedding ( str ) -- Name of word embedding to use","title":"createWaifu"},{"location":"commands/waifu/#deletewaifu","text":"Delete a waifu. 1 deleteWaifu -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu to delete","title":"deleteWaifu"},{"location":"commands/waifu/#savewaifu","text":"Save a waifu. 1 saveWaifu -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu to save","title":"saveWaifu"},{"location":"commands/waifu/#loadwaifu","text":"Load a waifu. 1 loadWaifu -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu to load","title":"loadWaifu"},{"location":"commands/waifu/#getwaifudetail","text":"Get the detail information of a waifu. 1 getWaifuDetail -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu","title":"getWaifuDetail"},{"location":"commands/waifu/#waifupredict","text":"Make prediction using waifu. 1 getWaifuDetail -n 'waifu name' Keyword Arguments: -n, --name ( str ) -- Name of waifu","title":"waifuPredict"},{"location":"file_structure/overview/","text":"File Structure Overview \u00b6 Animius uses various files, ranging from configs to Tensorflow model checkpoints. This overview will briefly explain how and where each of the objects is stored by default when using the console (this does not apply when using Animius as a python library or when directories are provided). It should also be noted that all config files created by Animius are in JSON. When you start Animius for the first time, the console will prompt you to choose a directory as the storage space for resources. This directory will contain all the files with the exception of \\user-config.json being at the root directory. config.json \u00b6 It should be noted that there is a clear distinction between \\config.json and \\user-config.json . \\config.json serves as a template for \\user-config.json , which should be created either manually or automatically at first launch. This way, when the user pulls updates from git, the configs will not be overwritten. Waifus (or Waifu-tachi) \u00b6 A Waifu, as the name suggests, is a set of models that are linked together to create an artificial intelligence agent \u2014 a Waifu. While waifus are stored individually as JSON files in the waifus folder, the \\waifus.json file contains information on all waifus for console usage. Models \u00b6 Unlike the Waifus, each model gets its own folder under the \\models\\ . A single file, \\models\\models.json stores information of all of the models. This also allows for models being stored outside of \\Models\\ (although this is strongly discouraged). For the sake of an example, we will have a single model named myModel . \\models\\myModel\\ will include a file \\Models\\myModel\\myModel.json containing its config. Model checkpoints and graphs will be stored in the same folder as myModel.json by default, while Tensorboard files will be stored in a folder defined by the user in model config. Model Configs \u00b6 Model configs, located under \\model_configs\\ have very similar structures as waifus: individual user-named JSON configs and a main model_configs.json . Each model config is an individual JSON file that is very similar to the config file of models, with the few exceptions of model-specific values such as names and epochs. Data \u00b6 It is often encouraged to store data in their raw forms, such as audio or words, so they can always be regenerated after changes in model structure. Nevertheless, it may be more convenient to store parsed data as numpy arrays. The saved files will be found in the \\Data\\ folder within their individual folders indicated in \\data\\data.json . Each folder will contain a JSON config and a .npz file generated by numpy. When storing data, there are also the options of saving separate copies of the model config and word embedding. This is to prevent changes that may be incompatible with the parsed data, such as sequence lengths and token indexes. These individual copies will be stored in folders within the directory of the JSON config and the .npz file. Word Embeddings \u00b6 Embeddings are stored under the \\embeddings\\ folder with a \\embeddings\\embeddings.json config. Each embedding has an individual folder containing a .npy numpy ndarrary file and two .pkl pickle files. No individual JSON file is stored for embeddings. File tree example \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Resources \u251c\u2500\u2500\u2500 waifus \u2502 \u251c\u2500\u2500\u2500 waifus.json \u2502 \u2514\u2500\u2500\u2500 yukino_waifu_config.json \u251c\u2500\u2500\u2500 models \u2502 \u251c\u2500\u2500\u2500 models.json \u2502 \u2514\u2500\u2500\u2500 myModel \u2502 \u251c\u2500\u2500\u2500 checkpoint \u2502 \u251c\u2500\u2500\u2500 myModel.json \u2502 \u251c\u2500\u2500\u2500 myModel_graph.pb \u2502 \u251c\u2500\u2500\u2500 myModel-0.data-00000 \u2502 \u2514\u2500\u2500\u2500 myModel-0.meta \u251c\u2500\u2500\u2500 model_configs \u2502 \u251c\u2500\u2500\u2500 model_configs.json \u2502 \u2514\u2500\u2500\u2500 myModelConfig.json \u251c\u2500\u2500\u2500 data \u2502 \u251c\u2500\u2500\u2500 data.json \u2502 \u2514\u2500\u2500\u2500 myData \u2502 \u251c\u2500\u2500\u2500 myData.json \u2502 \u2514\u2500\u2500\u2500 myData_np_arrays.npz \u2514\u2500\u2500\u2500 embeddings \u251c\u2500\u2500\u2500 embeddings.json \u2514\u2500\u2500\u2500 myEmbedding \u251c\u2500\u2500\u2500 myEmbedding.npy \u251c\u2500\u2500\u2500 myEmbedding_words.pkl_ \u2514\u2500\u2500\u2500 myEmbedding_words_to_index.pkl","title":"Overview"},{"location":"file_structure/overview/#file-structure-overview","text":"Animius uses various files, ranging from configs to Tensorflow model checkpoints. This overview will briefly explain how and where each of the objects is stored by default when using the console (this does not apply when using Animius as a python library or when directories are provided). It should also be noted that all config files created by Animius are in JSON. When you start Animius for the first time, the console will prompt you to choose a directory as the storage space for resources. This directory will contain all the files with the exception of \\user-config.json being at the root directory.","title":"File Structure Overview"},{"location":"file_structure/overview/#configjson","text":"It should be noted that there is a clear distinction between \\config.json and \\user-config.json . \\config.json serves as a template for \\user-config.json , which should be created either manually or automatically at first launch. This way, when the user pulls updates from git, the configs will not be overwritten.","title":"config.json"},{"location":"file_structure/overview/#waifus-or-waifu-tachi","text":"A Waifu, as the name suggests, is a set of models that are linked together to create an artificial intelligence agent \u2014 a Waifu. While waifus are stored individually as JSON files in the waifus folder, the \\waifus.json file contains information on all waifus for console usage.","title":"Waifus (or Waifu-tachi)"},{"location":"file_structure/overview/#models","text":"Unlike the Waifus, each model gets its own folder under the \\models\\ . A single file, \\models\\models.json stores information of all of the models. This also allows for models being stored outside of \\Models\\ (although this is strongly discouraged). For the sake of an example, we will have a single model named myModel . \\models\\myModel\\ will include a file \\Models\\myModel\\myModel.json containing its config. Model checkpoints and graphs will be stored in the same folder as myModel.json by default, while Tensorboard files will be stored in a folder defined by the user in model config.","title":"Models"},{"location":"file_structure/overview/#model-configs","text":"Model configs, located under \\model_configs\\ have very similar structures as waifus: individual user-named JSON configs and a main model_configs.json . Each model config is an individual JSON file that is very similar to the config file of models, with the few exceptions of model-specific values such as names and epochs.","title":"Model Configs"},{"location":"file_structure/overview/#data","text":"It is often encouraged to store data in their raw forms, such as audio or words, so they can always be regenerated after changes in model structure. Nevertheless, it may be more convenient to store parsed data as numpy arrays. The saved files will be found in the \\Data\\ folder within their individual folders indicated in \\data\\data.json . Each folder will contain a JSON config and a .npz file generated by numpy. When storing data, there are also the options of saving separate copies of the model config and word embedding. This is to prevent changes that may be incompatible with the parsed data, such as sequence lengths and token indexes. These individual copies will be stored in folders within the directory of the JSON config and the .npz file.","title":"Data"},{"location":"file_structure/overview/#word-embeddings","text":"Embeddings are stored under the \\embeddings\\ folder with a \\embeddings\\embeddings.json config. Each embedding has an individual folder containing a .npy numpy ndarrary file and two .pkl pickle files. No individual JSON file is stored for embeddings.","title":"Word Embeddings"},{"location":"file_structure/overview/#file-tree-example","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Resources \u251c\u2500\u2500\u2500 waifus \u2502 \u251c\u2500\u2500\u2500 waifus.json \u2502 \u2514\u2500\u2500\u2500 yukino_waifu_config.json \u251c\u2500\u2500\u2500 models \u2502 \u251c\u2500\u2500\u2500 models.json \u2502 \u2514\u2500\u2500\u2500 myModel \u2502 \u251c\u2500\u2500\u2500 checkpoint \u2502 \u251c\u2500\u2500\u2500 myModel.json \u2502 \u251c\u2500\u2500\u2500 myModel_graph.pb \u2502 \u251c\u2500\u2500\u2500 myModel-0.data-00000 \u2502 \u2514\u2500\u2500\u2500 myModel-0.meta \u251c\u2500\u2500\u2500 model_configs \u2502 \u251c\u2500\u2500\u2500 model_configs.json \u2502 \u2514\u2500\u2500\u2500 myModelConfig.json \u251c\u2500\u2500\u2500 data \u2502 \u251c\u2500\u2500\u2500 data.json \u2502 \u2514\u2500\u2500\u2500 myData \u2502 \u251c\u2500\u2500\u2500 myData.json \u2502 \u2514\u2500\u2500\u2500 myData_np_arrays.npz \u2514\u2500\u2500\u2500 embeddings \u251c\u2500\u2500\u2500 embeddings.json \u2514\u2500\u2500\u2500 myEmbedding \u251c\u2500\u2500\u2500 myEmbedding.npy \u251c\u2500\u2500\u2500 myEmbedding_words.pkl_ \u2514\u2500\u2500\u2500 myEmbedding_words_to_index.pkl","title":"File tree example"},{"location":"network/authentication/","text":"Network Authentication \u00b6 Since the server and client are able to communicate across different networks, authentication is required to prevent abusing hardware or stealing model information. Password \u00b6 When starting a server, the argument -p or --password is avaliable to set up passwords. Connections without the correct password will be closed. The password is not saved by the console, so it is expected for the user to pass in the argument every time. This also allows the password to be changed between sessions. If no argument is passed, the server will accept all connections. Client \u00b6 If the server has a password, the client must send the password string encrypted with AES ( encryption ) upon connection. No JSON format is required. If the password is incorrect, the connection will be closed. Otherwise, the connection will remain open and a 'success' response will be sent. If the server does not have a password, then the client is not expected to send anything.","title":"Authentication"},{"location":"network/authentication/#network-authentication","text":"Since the server and client are able to communicate across different networks, authentication is required to prevent abusing hardware or stealing model information.","title":"Network Authentication"},{"location":"network/authentication/#password","text":"When starting a server, the argument -p or --password is avaliable to set up passwords. Connections without the correct password will be closed. The password is not saved by the console, so it is expected for the user to pass in the argument every time. This also allows the password to be changed between sessions. If no argument is passed, the server will accept all connections.","title":"Password"},{"location":"network/authentication/#client","text":"If the server has a password, the client must send the password string encrypted with AES ( encryption ) upon connection. No JSON format is required. If the password is incorrect, the connection will be closed. Otherwise, the connection will remain open and a 'success' response will be sent. If the server does not have a password, then the client is not expected to send anything.","title":"Client"},{"location":"network/encryption/","text":"Network Encryption \u00b6 IMPORTANT | Animius no longer uses ANY encrytion. It sends plain strings/bytes instead. The following is outdated In short, Animius uses AES-CBC + base64 encryption. Initial Connection \u00b6 Upon connection, the server will send a unencrypted response containing the key and iv for AES-CBC. It should look something similar to: 1 2 3 4 5 6 7 8 9 { \"id\" : \"01:01\" , \"status\" : 0 , \"message\" : \"\" , \"data\" : { \"key\" : \"base64 encoded string\" , \"iv\" : \"base64 encoded string\" } } The client should decode the base64 strings to obtain the original bytes. Client sending \u00b6 When sending a JSON-formatted request (see the overview page for details) to the server, it must be converted bytes through UTF-8. Then, encrypt the message with AES-CBC with the recevied keys and IVs. Convert the encrypted bytes to a base64 string. Finally, encode the string into bytes with UTF-8 and send it. Client receiving \u00b6 Upon receiving the bytes, the client should decode it with UTF-8, obtaining a base64-encoded string. Then, decode the string with base64. Decrypt the decoded bytes using AES-CBC with the key and iv provided upon connection. Decode the bytes with UTF-8. The result should be a JSON string.","title":"Encryption"},{"location":"network/encryption/#network-encryption","text":"IMPORTANT | Animius no longer uses ANY encrytion. It sends plain strings/bytes instead. The following is outdated In short, Animius uses AES-CBC + base64 encryption.","title":"Network Encryption"},{"location":"network/encryption/#initial-connection","text":"Upon connection, the server will send a unencrypted response containing the key and iv for AES-CBC. It should look something similar to: 1 2 3 4 5 6 7 8 9 { \"id\" : \"01:01\" , \"status\" : 0 , \"message\" : \"\" , \"data\" : { \"key\" : \"base64 encoded string\" , \"iv\" : \"base64 encoded string\" } } The client should decode the base64 strings to obtain the original bytes.","title":"Initial Connection"},{"location":"network/encryption/#client-sending","text":"When sending a JSON-formatted request (see the overview page for details) to the server, it must be converted bytes through UTF-8. Then, encrypt the message with AES-CBC with the recevied keys and IVs. Convert the encrypted bytes to a base64 string. Finally, encode the string into bytes with UTF-8 and send it.","title":"Client sending"},{"location":"network/encryption/#client-receiving","text":"Upon receiving the bytes, the client should decode it with UTF-8, obtaining a base64-encoded string. Then, decode the string with base64. Decrypt the decoded bytes using AES-CBC with the key and iv provided upon connection. Decode the bytes with UTF-8. The result should be a JSON string.","title":"Client receiving"},{"location":"network/overview/","text":"Network Overview \u00b6 In addition to using the python console, Animius can also be accessed with a network TCP socket. This allows for user-friendly and extensive clients written in other languages. Server \u00b6 The server has the same requirements as using the python console, with the addition of networking. Client \u00b6 The client has no requirements other than networking. Python is not needed. To communicate with the server, simply use TCP messages. Although it is recommended for security, the client and the server are not required to be on the same network. See (gundamMC/Waifu-GUI) for a C# WPF example. Commands \u00b6 The server takes in JSON messages with the following format: 1 2 3 4 5 6 7 8 { \"command\" : \"foo\" , \"id\" : \"01:01\" , \"arguments\" : { \"boo\" : 2 , \"bar\" : \"MAX\" } } command takes in a string that specifies a function defined by the server while the dictionary arguments define the keyword arguments. For instance, the above code represents foo --boo=2 --bar='MAX' . id is simply a string identifier for the client. Responses \u00b6 The server responds in the following format: 1 2 3 4 5 6 7 8 9 { \"id\" : \"01:01\" , \"status\" : 0 , \"message\" : \"success\" , \"data\" : { \"foo\" : 2 , \"boo\" : \"bar\" } } id is the identifier that the client sends. The server simply returns the same id. status is a code that represents the following values 0 -> success 1 -> failure 2 -> argument error 3- > error (An argument error occurs when an argument is missing or has the wrong type, in contrary to an error) message is simply a message that provides additional information on the status. In failure or an error, it would provide the cause of such failure or error. data is a dictionary that contains the return values of the command. If the user queries for information on a model, data would include the information of the model. Note that data is subject to change for each command, while some commands may not even return anything in data (an empty dictionary will be used in that case to ensure that all responses contain a data ).","title":"Overview"},{"location":"network/overview/#network-overview","text":"In addition to using the python console, Animius can also be accessed with a network TCP socket. This allows for user-friendly and extensive clients written in other languages.","title":"Network Overview"},{"location":"network/overview/#server","text":"The server has the same requirements as using the python console, with the addition of networking.","title":"Server"},{"location":"network/overview/#client","text":"The client has no requirements other than networking. Python is not needed. To communicate with the server, simply use TCP messages. Although it is recommended for security, the client and the server are not required to be on the same network. See (gundamMC/Waifu-GUI) for a C# WPF example.","title":"Client"},{"location":"network/overview/#commands","text":"The server takes in JSON messages with the following format: 1 2 3 4 5 6 7 8 { \"command\" : \"foo\" , \"id\" : \"01:01\" , \"arguments\" : { \"boo\" : 2 , \"bar\" : \"MAX\" } } command takes in a string that specifies a function defined by the server while the dictionary arguments define the keyword arguments. For instance, the above code represents foo --boo=2 --bar='MAX' . id is simply a string identifier for the client.","title":"Commands"},{"location":"network/overview/#responses","text":"The server responds in the following format: 1 2 3 4 5 6 7 8 9 { \"id\" : \"01:01\" , \"status\" : 0 , \"message\" : \"success\" , \"data\" : { \"foo\" : 2 , \"boo\" : \"bar\" } } id is the identifier that the client sends. The server simply returns the same id. status is a code that represents the following values 0 -> success 1 -> failure 2 -> argument error 3- > error (An argument error occurs when an argument is missing or has the wrong type, in contrary to an error) message is simply a message that provides additional information on the status. In failure or an error, it would provide the cause of such failure or error. data is a dictionary that contains the return values of the command. If the user queries for information on a model, data would include the information of the model. Note that data is subject to change for each command, while some commands may not even return anything in data (an empty dictionary will be used in that case to ensure that all responses contain a data ).","title":"Responses"},{"location":"python/am.Chatbot/","text":"Module: am.Chatbot \u00b6 Overview \u00b6 Classes \u00b6 class ChatbotModel class CombinedChatbotModel class CombinedPredictionModel class Parse","title":"am.Chatbot"},{"location":"python/am.Chatbot/#module-amchatbot","text":"","title":"Module: am.Chatbot"},{"location":"python/am.Chatbot/#overview","text":"","title":"Overview"},{"location":"python/am.Chatbot/#classes","text":"class ChatbotModel class CombinedChatbotModel class CombinedPredictionModel class Parse","title":"Classes"},{"location":"python/am.IntentNER/","text":"Module: am.IntentNER \u00b6 Overview \u00b6 Classes \u00b6 class IntentNERModel class Parse","title":"am.IntentNER"},{"location":"python/am.IntentNER/#module-amintentner","text":"","title":"Module: am.IntentNER"},{"location":"python/am.IntentNER/#overview","text":"","title":"Overview"},{"location":"python/am.IntentNER/#classes","text":"class IntentNERModel class Parse","title":"Classes"},{"location":"python/am.SpeakerVerification/","text":"Module: am.SpeakerVerification \u00b6 Overview \u00b6 Classes \u00b6 class MFCC class SpeakerVerificationModel","title":"am.SpeakerVerification"},{"location":"python/am.SpeakerVerification/#module-amspeakerverification","text":"","title":"Module: am.SpeakerVerification"},{"location":"python/am.SpeakerVerification/#overview","text":"","title":"Overview"},{"location":"python/am.SpeakerVerification/#classes","text":"class MFCC class SpeakerVerificationModel","title":"Classes"},{"location":"python/am.Utils/","text":"Module: am.Utils \u00b6 Overview \u00b6 Functions \u00b6 get_system_info(...) shuffle(...) get_mini_batches(...) get_length(...) sentence_to_index(...) set_sequence_length(...) freeze_graph(...) optimize(...) am.Utils.get_system_info \u00b6 am.Utils.get_system_info() Defined in animius/Utils.py . Returns basic hardware and runtime information. This function use Python libraries psutil and pynvml to obtain system information. For example: 1 2 3 {'cpu_percent': 25.5, 'cpu_count': 6, 'mem_total': 16307, 'mem_available': 11110, 'mem_percent': 31.9, 'disk_total': 339338, 'disk_used': 237581, 'disk_percent': 70.0, 'boot_time': 1556635120.0,'gpu_driver_version': '430.39', 'gpu_device_list': [ {'gpu_name': 'GeForce GTX 1060 6GB', 'gpu_mem_total': 6144, 'gpu_mem_used': 449, 'gpu_mem_percent': 0}]} GPU information won't be shown if your system does not contain any GPU. Args: None Returns: A dict contains basic hardware and system information.","title":"am.Utils"},{"location":"python/am.Utils/#module-amutils","text":"","title":"Module: am.Utils"},{"location":"python/am.Utils/#overview","text":"","title":"Overview"},{"location":"python/am.Utils/#functions","text":"get_system_info(...) shuffle(...) get_mini_batches(...) get_length(...) sentence_to_index(...) set_sequence_length(...) freeze_graph(...) optimize(...)","title":"Functions"},{"location":"python/am.Utils/#amutilsget_system_info","text":"am.Utils.get_system_info() Defined in animius/Utils.py . Returns basic hardware and runtime information. This function use Python libraries psutil and pynvml to obtain system information. For example: 1 2 3 {'cpu_percent': 25.5, 'cpu_count': 6, 'mem_total': 16307, 'mem_available': 11110, 'mem_percent': 31.9, 'disk_total': 339338, 'disk_used': 237581, 'disk_percent': 70.0, 'boot_time': 1556635120.0,'gpu_driver_version': '430.39', 'gpu_device_list': [ {'gpu_name': 'GeForce GTX 1060 6GB', 'gpu_mem_total': 6144, 'gpu_mem_used': 449, 'gpu_mem_percent': 0}]} GPU information won't be shown if your system does not contain any GPU. Args: None Returns: A dict contains basic hardware and system information.","title":"am.Utils.get_system_info"},{"location":"python/am/","text":"Module: am \u00b6 Defined in animius/__init__.py . Overview \u00b6 Modules \u00b6 Chatbot IntentNER SpeakerVerification Utils Classes \u00b6 class ChatbotData class CombinedPredictionData class Commands class Console class IntentNERData class Model class ModelConfig class SpeakerVerificationData class SubtitleParser class Waifu am.Commands \u00b6 Defined in animius/Commands.py . Class am.Commands contains the whole details of console commands, such as their arguments or their descriptions. __init__ \u00b6 Args: console (am.Console) -- reference to an am.Console object. Properties \u00b6 None Methods \u00b6 __iter__ \u00b6 __iter__() Returns an iterator for the command dict. Args: None Returns: A reference to the iterator for the command dict. __getitem__ \u00b6 __getitem__(item) Returns detail information of a command. For example, __getitem__('exportWaifu') will return: 1 2 3 4 5 6 7 8 9 [ console.export_waifu, { '-n': ['name', 'str', 'Name of waifu'], '-p': ['path', 'str', 'Path to export file'] }, 'Export a waifu', \"exportWaifu -n 'waifu name' -p 'path_name'\" ] Args: item ( str ) -- command name. Returns: A dict similar to the example above. am.Console \u00b6 Defined in animius/Console.py . Class am.Console includes the method corresponding to each command, a queue which controls the workflow, and a command handler. __init__ \u00b6 Args: init_directory ( str ) -- the path to the directory in which animius saves resources. (Optional) Properties \u00b6 Methods \u00b6 am.Console.server \u00b6 am.Console.server(console, port, local=True, password='', max_clients=10) Start socket server on specific port. Args: console ( am.Console ) -- reference to an am.Console object. port ( int ) -- specific port which the socket server listening on. local ( boolean ) -- whether or not the server runs on local address. (as known as '127.0.0.1' or 'localhost') password ( str ) -- password which requires when clients creating a connection with the socket server. (optional) max_clients ( int ) -- specific number of clients the server can communicate with. (optional) Returns: The reference to a thread object which socket server is running on. am.ModelConfig \u00b6 Defined in animius/ModelConfig.py . __init__ \u00b6 Args: cls ( str ) -- type of model config, must be included in ['SpeakerVerification', 'Chatbot', 'IntentNER', 'CombinedChatbot']. config ( dict ) -- dict of config. (Optional) hyperparameters ( dict ) -- dict of hyperparameters. (Optional) model_structure ( dict ) -- dict of model structures. (Optional) Properties \u00b6 config hyperparameters model_structure Methods \u00b6 apply_defaults \u00b6 apply_defaults() Apply default model config. For example: 1 2 config = am.ModelConfig(cls=\"Chatbot\") config.apply_defaults() Args: None Returns: None save \u00b6 save(directory, name='model_config') Save model config to local file. Args: directory ( str ) -- directory where you want to save config file. name * ( str ) -- name of model config file. (Optional) Returns: directory where config file saves. load (Class method) \u00b6 load(cls, directory, name='model_config') Load model config from local file. Args: cls ( str ) -- type of model config, must be included in ['SpeakerVerification', 'Chatbot', 'IntentNER', 'CombinedChatbot']. directory ( str ) -- directory where you want to save config file. name * ( str ) -- name of model config file. (Optional) Returns: The reference to the am.ModelConfig object.","title":"am"},{"location":"python/am/#module-am","text":"Defined in animius/__init__.py .","title":"Module: am"},{"location":"python/am/#overview","text":"","title":"Overview"},{"location":"python/am/#modules","text":"Chatbot IntentNER SpeakerVerification Utils","title":"Modules"},{"location":"python/am/#classes","text":"class ChatbotData class CombinedPredictionData class Commands class Console class IntentNERData class Model class ModelConfig class SpeakerVerificationData class SubtitleParser class Waifu","title":"Classes"},{"location":"python/am/#amcommands","text":"Defined in animius/Commands.py . Class am.Commands contains the whole details of console commands, such as their arguments or their descriptions.","title":"am.Commands"},{"location":"python/am/#9595init9595","text":"Args: console (am.Console) -- reference to an am.Console object.","title":"__init__"},{"location":"python/am/#properties","text":"None","title":"Properties"},{"location":"python/am/#methods","text":"","title":"Methods"},{"location":"python/am/#9595iter9595","text":"__iter__() Returns an iterator for the command dict. Args: None Returns: A reference to the iterator for the command dict.","title":"__iter__"},{"location":"python/am/#9595getitem9595","text":"__getitem__(item) Returns detail information of a command. For example, __getitem__('exportWaifu') will return: 1 2 3 4 5 6 7 8 9 [ console.export_waifu, { '-n': ['name', 'str', 'Name of waifu'], '-p': ['path', 'str', 'Path to export file'] }, 'Export a waifu', \"exportWaifu -n 'waifu name' -p 'path_name'\" ] Args: item ( str ) -- command name. Returns: A dict similar to the example above.","title":"__getitem__"},{"location":"python/am/#amconsole","text":"Defined in animius/Console.py . Class am.Console includes the method corresponding to each command, a queue which controls the workflow, and a command handler.","title":"am.Console"},{"location":"python/am/#9595init9595_1","text":"Args: init_directory ( str ) -- the path to the directory in which animius saves resources. (Optional)","title":"__init__"},{"location":"python/am/#properties_1","text":"","title":"Properties"},{"location":"python/am/#methods_1","text":"","title":"Methods"},{"location":"python/am/#amconsoleserver","text":"am.Console.server(console, port, local=True, password='', max_clients=10) Start socket server on specific port. Args: console ( am.Console ) -- reference to an am.Console object. port ( int ) -- specific port which the socket server listening on. local ( boolean ) -- whether or not the server runs on local address. (as known as '127.0.0.1' or 'localhost') password ( str ) -- password which requires when clients creating a connection with the socket server. (optional) max_clients ( int ) -- specific number of clients the server can communicate with. (optional) Returns: The reference to a thread object which socket server is running on.","title":"am.Console.server"},{"location":"python/am/#ammodelconfig","text":"Defined in animius/ModelConfig.py .","title":"am.ModelConfig"},{"location":"python/am/#9595init9595_2","text":"Args: cls ( str ) -- type of model config, must be included in ['SpeakerVerification', 'Chatbot', 'IntentNER', 'CombinedChatbot']. config ( dict ) -- dict of config. (Optional) hyperparameters ( dict ) -- dict of hyperparameters. (Optional) model_structure ( dict ) -- dict of model structures. (Optional)","title":"__init__"},{"location":"python/am/#properties_2","text":"config hyperparameters model_structure","title":"Properties"},{"location":"python/am/#methods_2","text":"","title":"Methods"},{"location":"python/am/#apply_defaults","text":"apply_defaults() Apply default model config. For example: 1 2 config = am.ModelConfig(cls=\"Chatbot\") config.apply_defaults() Args: None Returns: None","title":"apply_defaults"},{"location":"python/am/#save","text":"save(directory, name='model_config') Save model config to local file. Args: directory ( str ) -- directory where you want to save config file. name * ( str ) -- name of model config file. (Optional) Returns: directory where config file saves.","title":"save"},{"location":"python/am/#load-class-method","text":"load(cls, directory, name='model_config') Load model config from local file. Args: cls ( str ) -- type of model config, must be included in ['SpeakerVerification', 'Chatbot', 'IntentNER', 'CombinedChatbot']. directory ( str ) -- directory where you want to save config file. name * ( str ) -- name of model config file. (Optional) Returns: The reference to the am.ModelConfig object.","title":"load (Class method)"},{"location":"quick start/commands/","text":"Quick Start \u00b6 This guide will go over the console module of Animius, am.Console , and how the conosle provides a set a commands to simplify the interaction process while automating a lot of the house-keeping mess. This guide assumes that you have already read the Quick Start Overview and is familiar with Animius's models Starting console \u00b6 To start the console, simply type in animius in your command line. If you installed animius with docker, the console should start automatically when you run an image. At first, the console will ask you to provide a directory to save data in. If your input is empty, Console will choose the default path. We highly recommend changing this path. 1 2 Please enter the data directory to save data in: Default (\\...\\animius\\resources\\) Now, the console will wait for your input - a command. Set up a model config \u00b6 In order to create a model and ultimately a waifu, we will have to create a model config first. In this example, we will be creating an intent-NER model (You can read more about Intent NER here). To begin, let's create an Intent NER model config called myModelConfig . 1 createModelConfig --name 'myModelConfig' --type 'IntentNER' With getModelConfigs , which reveals a list of model configs, you can verify that myModelConfig has been created and loaded. If you like, you can also get more insight into the model config values with getModelConfigDetails . (Note that --name and -n can be used interchangably.) 1 2 3 getModelConfigs getModelConfigDetails -n 'myModelConfig' We will be coming back to the model config after creating the data. Prepare the data \u00b6 Data is essential when training models. For Intent NER, which takes in English sentences as input, the data object requires a word embedding to both parse data and to create a model. So, let us begin by creating a data named myData . 1 createData --name 'myData' --model_config 'myModelConfig' The data equivalent of getModelConfigs and getModelConfigDetails are getData and getDataDetails . Setting up the word embedding \u00b6 Next, download a word embedding (we recommend glove) and the Intent NER Data from our resources page . Extract the zip file and place the folder somewhere safe. To enable the parsing of English text, we will have to use a word embedding. We can create an embedding object with createEmbedding : 1 createEmbedding --name 'myEmbedding' --path '/some/path/to/embedding.txt' --vocab_size 50000 The vocab size parameter is optional but recommended to prevent loading enormous embeddings that take up too much resource. Importing data \u00b6 We can import the data by using: 1 intentNERDataAddParseDatafolder --name 'myData' --path 'some/path/to/data_folder/' Now, the data will be parsed and stored in myData . You can have a closer look with getModelConfigDetails . Setup the Model \u00b6 After creating model config and data, we can create the model now. 1 createModel -n 'myModel' -t 'IntentNER' --model_config 'myModelConfig' --data 'myData' The data equivalent of getModelConfigs and getModelConfigDetails are getModels and getModelDetails . Training \u00b6 Now we need to train our model, which means making the model learn from the data we prepared. Let's test it out by training 10 epochs. An epoch is just a cycle during which the model trains over the entire training set. 1 train -n 'myModel' -e 10 Training will be done in the background by another thread, and you can cancel the training process by using stopTrain -n 'myModel' . The Console System \u00b6 Saving \u00b6 The console provides an automatic clean saving system. To save any object, simple use the command save{Type} . For instance, to save a model config, use saveModelConfig -n 'myModelConfig' . To save a data, saveData . And, to save a model, saveModel . And, please remember to save the console also, or else your created objects will not be recognized the next time you start animius. To save the console, simply use: 1 save Loading \u00b6 A item created in the console will be automatically loaded. However, when restarting a console, an item will not be loaded to save performance. Thus, before an object can be used, it must be loaded with the load{Type} command. This is similar to the save command. (e.g. loadModelConfig , loadData ) Deleting \u00b6 If you would like to delete an object from the console, simply use delete{Type} . This will remove the object from console but will not remove the actual file storage. That is, any save files will remain. See file structure Creating your Waifu \u00b6 Now, this tutorial will jump a bit from the IntentNER model to a CombinedChatbot model to give a broader sense of using console. We will assume that we have already created a CombinedChatbot model called 'myCombinedChatbot' and a word embedding named 'myEmbedding'. Now, create your waifu with createWaifu . 1 createWaifu -n 'myWaifu' --combined_chatbot_model 'myCombinedChatbot' --embedding 'myEmbedding' We can take a sneak peak with getWaifuDetail -n 'myWaifu' . Prediction \u00b6 To make a prediction (also referred to as inference) using our waifu, simply use waifuPredict . 1 waifuPredict -n 'myWaifu' --sentence 'Hello world!' Other commands \u00b6 We have covered the basics of using commands to interact with the console in this tutorial. There are, nevertheless, much more commands that you can use to customize your workflow and your virutal assistant. To learn more about commands, visit the commands section .","title":"Commands"},{"location":"quick start/commands/#quick-start","text":"This guide will go over the console module of Animius, am.Console , and how the conosle provides a set a commands to simplify the interaction process while automating a lot of the house-keeping mess. This guide assumes that you have already read the Quick Start Overview and is familiar with Animius's models","title":"Quick Start"},{"location":"quick start/commands/#starting-console","text":"To start the console, simply type in animius in your command line. If you installed animius with docker, the console should start automatically when you run an image. At first, the console will ask you to provide a directory to save data in. If your input is empty, Console will choose the default path. We highly recommend changing this path. 1 2 Please enter the data directory to save data in: Default (\\...\\animius\\resources\\) Now, the console will wait for your input - a command.","title":"Starting console"},{"location":"quick start/commands/#set-up-a-model-config","text":"In order to create a model and ultimately a waifu, we will have to create a model config first. In this example, we will be creating an intent-NER model (You can read more about Intent NER here). To begin, let's create an Intent NER model config called myModelConfig . 1 createModelConfig --name 'myModelConfig' --type 'IntentNER' With getModelConfigs , which reveals a list of model configs, you can verify that myModelConfig has been created and loaded. If you like, you can also get more insight into the model config values with getModelConfigDetails . (Note that --name and -n can be used interchangably.) 1 2 3 getModelConfigs getModelConfigDetails -n 'myModelConfig' We will be coming back to the model config after creating the data.","title":"Set up a model config"},{"location":"quick start/commands/#prepare-the-data","text":"Data is essential when training models. For Intent NER, which takes in English sentences as input, the data object requires a word embedding to both parse data and to create a model. So, let us begin by creating a data named myData . 1 createData --name 'myData' --model_config 'myModelConfig' The data equivalent of getModelConfigs and getModelConfigDetails are getData and getDataDetails .","title":"Prepare the data"},{"location":"quick start/commands/#setting-up-the-word-embedding","text":"Next, download a word embedding (we recommend glove) and the Intent NER Data from our resources page . Extract the zip file and place the folder somewhere safe. To enable the parsing of English text, we will have to use a word embedding. We can create an embedding object with createEmbedding : 1 createEmbedding --name 'myEmbedding' --path '/some/path/to/embedding.txt' --vocab_size 50000 The vocab size parameter is optional but recommended to prevent loading enormous embeddings that take up too much resource.","title":"Setting up the word embedding"},{"location":"quick start/commands/#importing-data","text":"We can import the data by using: 1 intentNERDataAddParseDatafolder --name 'myData' --path 'some/path/to/data_folder/' Now, the data will be parsed and stored in myData . You can have a closer look with getModelConfigDetails .","title":"Importing data"},{"location":"quick start/commands/#setup-the-model","text":"After creating model config and data, we can create the model now. 1 createModel -n 'myModel' -t 'IntentNER' --model_config 'myModelConfig' --data 'myData' The data equivalent of getModelConfigs and getModelConfigDetails are getModels and getModelDetails .","title":"Setup the Model"},{"location":"quick start/commands/#training","text":"Now we need to train our model, which means making the model learn from the data we prepared. Let's test it out by training 10 epochs. An epoch is just a cycle during which the model trains over the entire training set. 1 train -n 'myModel' -e 10 Training will be done in the background by another thread, and you can cancel the training process by using stopTrain -n 'myModel' .","title":"Training"},{"location":"quick start/commands/#the-console-system","text":"","title":"The Console System"},{"location":"quick start/commands/#saving","text":"The console provides an automatic clean saving system. To save any object, simple use the command save{Type} . For instance, to save a model config, use saveModelConfig -n 'myModelConfig' . To save a data, saveData . And, to save a model, saveModel . And, please remember to save the console also, or else your created objects will not be recognized the next time you start animius. To save the console, simply use: 1 save","title":"Saving"},{"location":"quick start/commands/#loading","text":"A item created in the console will be automatically loaded. However, when restarting a console, an item will not be loaded to save performance. Thus, before an object can be used, it must be loaded with the load{Type} command. This is similar to the save command. (e.g. loadModelConfig , loadData )","title":"Loading"},{"location":"quick start/commands/#deleting","text":"If you would like to delete an object from the console, simply use delete{Type} . This will remove the object from console but will not remove the actual file storage. That is, any save files will remain. See file structure","title":"Deleting"},{"location":"quick start/commands/#creating-your-waifu","text":"Now, this tutorial will jump a bit from the IntentNER model to a CombinedChatbot model to give a broader sense of using console. We will assume that we have already created a CombinedChatbot model called 'myCombinedChatbot' and a word embedding named 'myEmbedding'. Now, create your waifu with createWaifu . 1 createWaifu -n 'myWaifu' --combined_chatbot_model 'myCombinedChatbot' --embedding 'myEmbedding' We can take a sneak peak with getWaifuDetail -n 'myWaifu' .","title":"Creating your Waifu"},{"location":"quick start/commands/#prediction","text":"To make a prediction (also referred to as inference) using our waifu, simply use waifuPredict . 1 waifuPredict -n 'myWaifu' --sentence 'Hello world!'","title":"Prediction"},{"location":"quick start/commands/#other-commands","text":"We have covered the basics of using commands to interact with the console in this tutorial. There are, nevertheless, much more commands that you can use to customize your workflow and your virutal assistant. To learn more about commands, visit the commands section .","title":"Other commands"},{"location":"quick start/overview/","text":"Get Started with Animius \u00b6 Animius is an open-source deep-learning library for creating AI virtual assistants. Animius offers both a user-friendly console for begginers and a Python API for developers to add their own functionalities into their AIs. See the sections below to get started. Dissecting your Waifu \u00b6 Waifu \u00b6 Each AI is called a \"waifu\" in Animius. A waifu functions by incorporating various deep learning models together and transforming their predictions. Said DL models are called \"models\" ( easy? ). Basically, waifus are powered by models. Models \u00b6 There are, of course, a variety of models in Animius, and they are separated by their usage. For instance, a model can be a speaker verification model (since it verifies the speaker). These models, nevertheless, are only the blueprints for you to build upon. You, as the user, provides a model config and data when creating a model. Introduction to Machine Learning \u00b6 Models are Machine Learning models (Deep Learning is just a branch of Machine Learning). Essentially, they are mathematical algorithms that train on existing data and will make predictions based on such data. For instance, you can train a chatbot model on speech data from Jon Snow in Game of Thrones. Then, when you ask the model to make a response to your sentence, let's say \"How's it going,\" the model will respond accordingly. Winter is coming. To learn more about machine learning fundamentals and concepts, consider taking the Stanford University Machine Learninig MOOC by Andrew Ng and his Deep Learning Specialization . Model config \u00b6 A model config has three parts: config, model structure, and hyperparameters. The config section includes basic information that applies to all models, such as the device it is running on, the type of model, the epoch (See training), and tensorboard location. The model structure section, meanwhile, defines the mathematical structure of the deep learning algorithms and thus varies across different types of models. For instance, you can change the number of nodes and layers a model will have, thus effectively increasing or decreasing the performance and resource usage of a model. Nevertheless, we do not recommend changing the default values unless you know what you are doing. Lastly, the hyperparameters define the training aspect of the model, including values such as learning rate, batch size, and optimizer. Like the model structures, we do not recommend changing the default values. Data \u00b6 A data object is simply a data parser. That is, it reads data stored as files on your drives and stores the values. For some models, a word embedding is also required before parsing files and passing the data into a model. Word embedding \u00b6 A word embedding is exactly what it sounds like. It translates word tokens into numerical vectors. Conclusion \u00b6 Thus, to wrap up, the basic structure of your AI would be: a waifu including various models. Each model contains a model config and a data object For some models, the data object will contain a word embedding. Creating your Waifu \u00b6 To create your own waifu, it is simply. Recall the structure detailed above. All you have to do is start from the bottom and move your way up. In other words, gather data, prepare model configs, create models using these data and model configs, train the models, and compile them into a waifu. Now, there are two ways you can create your own AI: Python API and Console. The Python API is recommended for the experienced developers who wish to add their own functionalities to their AIs, and the console is recommended for beginners who like a more user-friendly experienced without writing code (you will be using commands instead).","title":"Overview"},{"location":"quick start/overview/#get-started-with-animius","text":"Animius is an open-source deep-learning library for creating AI virtual assistants. Animius offers both a user-friendly console for begginers and a Python API for developers to add their own functionalities into their AIs. See the sections below to get started.","title":"Get Started with Animius"},{"location":"quick start/overview/#dissecting-your-waifu","text":"","title":"Dissecting your Waifu"},{"location":"quick start/overview/#waifu","text":"Each AI is called a \"waifu\" in Animius. A waifu functions by incorporating various deep learning models together and transforming their predictions. Said DL models are called \"models\" ( easy? ). Basically, waifus are powered by models.","title":"Waifu"},{"location":"quick start/overview/#models","text":"There are, of course, a variety of models in Animius, and they are separated by their usage. For instance, a model can be a speaker verification model (since it verifies the speaker). These models, nevertheless, are only the blueprints for you to build upon. You, as the user, provides a model config and data when creating a model.","title":"Models"},{"location":"quick start/overview/#introduction-to-machine-learning","text":"Models are Machine Learning models (Deep Learning is just a branch of Machine Learning). Essentially, they are mathematical algorithms that train on existing data and will make predictions based on such data. For instance, you can train a chatbot model on speech data from Jon Snow in Game of Thrones. Then, when you ask the model to make a response to your sentence, let's say \"How's it going,\" the model will respond accordingly. Winter is coming. To learn more about machine learning fundamentals and concepts, consider taking the Stanford University Machine Learninig MOOC by Andrew Ng and his Deep Learning Specialization .","title":"Introduction to Machine Learning"},{"location":"quick start/overview/#model-config","text":"A model config has three parts: config, model structure, and hyperparameters. The config section includes basic information that applies to all models, such as the device it is running on, the type of model, the epoch (See training), and tensorboard location. The model structure section, meanwhile, defines the mathematical structure of the deep learning algorithms and thus varies across different types of models. For instance, you can change the number of nodes and layers a model will have, thus effectively increasing or decreasing the performance and resource usage of a model. Nevertheless, we do not recommend changing the default values unless you know what you are doing. Lastly, the hyperparameters define the training aspect of the model, including values such as learning rate, batch size, and optimizer. Like the model structures, we do not recommend changing the default values.","title":"Model config"},{"location":"quick start/overview/#data","text":"A data object is simply a data parser. That is, it reads data stored as files on your drives and stores the values. For some models, a word embedding is also required before parsing files and passing the data into a model.","title":"Data"},{"location":"quick start/overview/#word-embedding","text":"A word embedding is exactly what it sounds like. It translates word tokens into numerical vectors.","title":"Word embedding"},{"location":"quick start/overview/#conclusion","text":"Thus, to wrap up, the basic structure of your AI would be: a waifu including various models. Each model contains a model config and a data object For some models, the data object will contain a word embedding.","title":"Conclusion"},{"location":"quick start/overview/#creating-your-waifu","text":"To create your own waifu, it is simply. Recall the structure detailed above. All you have to do is start from the bottom and move your way up. In other words, gather data, prepare model configs, create models using these data and model configs, train the models, and compile them into a waifu. Now, there are two ways you can create your own AI: Python API and Console. The Python API is recommended for the experienced developers who wish to add their own functionalities to their AIs, and the console is recommended for beginners who like a more user-friendly experienced without writing code (you will be using commands instead).","title":"Creating your Waifu"}]}